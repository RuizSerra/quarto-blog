[
  {
    "objectID": "food.html",
    "href": "food.html",
    "title": "Some things I have cooked and/or baked",
    "section": "",
    "text": "In no particular order.\n\n\n\nSourdough rye country loaf (one of many)\n\n\n\n\n\nOctopus (cooking)\n\n\n\n\n\nOctopus (cooked)\n\n\n\n\n\nFennel and orange spatchcock chicken\n\n\n\n\n\nPickled fennel\n\n\n\n\n\nFocaccia\n\n\n\n\n\nCLT on rye sourdough\n\n\n\n\n\nSpinach and ricotta cappelletti\n\n\n\n\n\nHot-X buns\n\n\n\n\n\nPoached eggs on sourdough with random veg\n\n\n\n\n\nFocaccia\n\n\n\n\n\nSnapper, kale stem salsa verde, veg\n\n\n\n\n\nPulpo a la Gallega, escalivada, sourdough country loaf\n\n\n\n\n\nTomatoes from my friends’ garden\n\n\n\n\n\nEggs and mushrooms on toast (salt your tomato)\n\n\n\n\n\nA loaf\n\n\n\n\n\nA loaf, sliced\n\n\n\n\n\nSourdough loaf (about to go in the oven)\n\n\n\n\n\nSourdough fruit loaf"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jaime Ruiz Serra",
    "section": "",
    "text": "PhD candidate\nModelling and Simulation Research Group\nCentre for Complex Systems\nThe University of Sydney\nAs a PhD researcher, I explore the interplay between individual agency and collective dynamics, focusing on how incentives shape this relationship. My work leverages agent-based modelling in computational economics and draws from game theory, evolutionary theory, information theory, and social psychology.\nPassionate about empowering individuals equitably and sustainably, I believe that democratizing information and technology, along with fostering local communities, will have the greatest impact toward this goal.\nWith studies in robotics and mechatronics engineering, I have experience in machine learning and computer vision research. I’m a certified AWS Solutions Architect Associate with three years of professional experience in cloud infrastructure for the financial sector and over eight years of Python expertise in automation, data engineering, and machine learning."
  },
  {
    "objectID": "index.html#selected-publications",
    "href": "index.html#selected-publications",
    "title": "Jaime Ruiz Serra",
    "section": "Selected Publications",
    "text": "Selected Publications\nRuiz-Serra J, Sweeney P, and Harré MS. Factorised Active Inference for Strategic Multi-Agent Interactions. In AAMAS ’25: Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems. Detroit, USA, May 2025.\nRuiz-Serra J, White J, Petrie S, Kameneva T, and McCarthy C. Learning scene representations for human-assistive displays using self-attention networks. ACM Trans. Multimedia Comput. Commun. Appl., 2024. DOI:10.1145/3650111\nRuiz-Serra J and Harré MS. Inverse Reinforcement Learning as the Algorithmic Basis for Theory of Mind: Current Methods and Open Problems. Algorithms, 2023, 16, 68. DOI:10.3390/a16020068\nRuiz-Serra J, White J, Petrie S, Kameneva T, and McCarthy C. Towards self-attention based visual navigation in the real world. In Proceedings of the 2022 Australasian Conference on Robotics and Automation (ACRA 2022). Brisbane, Australia, December 2022. arXiv:2209.07043\nMore on Scholar"
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jaime Ruiz Serra",
    "section": "Education",
    "text": "Education\nThe University of Sydney (Sydney, AU)\nPhD, Complex Systems (Computer Science)\nOct 2022 – Present\nMITx on edX (Online)\nMicroMasters, Statistics and Data Science\nMar 2021 – Nov 2022\nSwinburne University of Technology (Melbourne, AU)\nBEng (Hons), Robotics and Mechatronics\nFeb 2016 – Dec 2020\nCATC Design School (Melborune, AU)\nDipDes, Graphic Design\nJun 2013 – May 2014"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jaime Ruiz Serra",
    "section": "Experience",
    "text": "Experience\nThe University of Sydney (Sydney, AU)\nTeaching Assistant, Machine Learning, Complex Systems\nFeb 2023 – Nov 2024\nSwinburne University of Technology (Remote/Melbourne, AU)\nResearch Assistant, Deep Reinforcement Learning, Computer Vision\nSep 2020 – Jan 2024\nNational Australia Bank (Remote/Melbourne, AU)\nAnalyst, Engineer, Cloud Infrastructure (AWS)\nJan 2018 – Sep 2020\nYouth Without Borders (Melbourne, AU)\nVictoria Staffing Manager, Spark Engineering Camp\nNov 2016 – Sep 2017\nMore on LinkedIn"
  },
  {
    "objectID": "posts/GitHub-Copilot-free/index.html",
    "href": "posts/GitHub-Copilot-free/index.html",
    "title": "GitHub Copilot AI for free (for students and academics)",
    "section": "",
    "text": "I learned we can get free access to GitHub Copilot (AI programming assistant, built into VS Code), and wanted to share the process in case you are interested. Note the instructions below are tailored to “students”, but academics may also get access as “teachers”.\nRequirements:\n\nA GitHub account\nA student email address (abcd1234@uni.sydney.edu.au)\n\nSteps (general gist):\n\nAdd your student email address (i.e. unikey@uni.sydney.edu.au; not staff email address) to your GitHub account at https://github.com/settings/emails\nSign up for GitHub Global Campus https://education.github.com/students and submit a “GitHub benefits” request (https://education.github.com/discount_requests/application)\nWait 3-4 days for the email to be verified, you will receive a welcome email from edu-noreply@github.com. At this point, your GitHub profile should show a PRO badge on the left column (see e.g. https://github.com/RuizSerra/)\nEnable GitHub Copilot at https://github.com/settings/copilot\nInstall the Copilot extension in Visual Studio Code, then enable Copilot (ensure you are signed in to your GitHub account in VS Code)\nEnjoy the coding efficiency boost with your new AI pair-programmer\n\nSee also:\n\n[Announcement] GitHub Copilot now available for Teachers (2022/09/08)\nStep-by-Step: Setting Up GitHub Student and GitHub Copilot as an Authenticated Student Developer"
  },
  {
    "objectID": "posts/C3-2023-symposium/index.html",
    "href": "posts/C3-2023-symposium/index.html",
    "title": "Complexity, Criticality, Computation Symposium (C3) 2023",
    "section": "",
    "text": "The C3-2023 Symposium took place in Heron Island, QLD, Australia, in January 2023. Complex Systems researchers from around the globe got together for an enriching week of presentations and conversations, snorkeling and relaxation."
  },
  {
    "objectID": "posts/translating-code-different-language/index.html",
    "href": "posts/translating-code-different-language/index.html",
    "title": "Translating an unwieldy codebase",
    "section": "",
    "text": "I got access to a model that I want to use as a baseline for my research, but (i) it is in MATLAB and I prefer to work in Python, and (ii) it consists of a single 1000-line function with no modularity or use of classes/objects.\nMy first attempt at converting the code to Python was to use matlab2python, which did an OK job at translating the script, but had issues with 0-indexing (in Python) vs 1-indexing (in Matlab) and I believe it didn’t quite get some of the matrix operations right as numpy operations. As a result, after a bit of debugging, I got the Python code to run without throwing errors (hoorray!), but numerically something was off, since the simulation reached a stop condition five iterations in, when the Matlab version was able to run indefintely (irrespective of random seeds). Debugging this would have been a nightmare, so I needed an alternative approach.\nMy supervisor suggested breaking down the code into small functional components that I could analyse and understand, including data type use, array sizes, etc., and test each component individually.\nTo do so, I first refactored the single Matlab function into a handful of smaller functions under a main function, and then translated each to Python. To be able to test them, I ran the program saving the state of the model at various points, with\n% model code ...\nsave('test-data/1.mat')\n% more model code ...\nsave('test-data/2.mat')\n% ...\nand then loaded the model state into a Jupyter notebook to test the functions, using\nimport numpy as np\nimport scipy.io\n\nmat = scipy.io.loadmat('test-data/1.mat')\n\nt = mat['t'].item() - 1 # int (-1 because zero-index in Python)\n\nstock = mat['stock'].squeeze()  # (1, F) -&gt; (F,)\nprice = mat['price'][t]         # (T, F) -&gt; (F,)\n\na, b = my_python_function(stock, price)\n\nassert np.all(a == mat['a'].squeeze())\nassert np.all(b == mat['b'].squeeze())\nThis allows me to work through the model, ensuring consistency at any arbitrary point in the flow of the function.\nFor larger functions that were harder to debug in one go, I applied the same technique within the function itself, checking the variables for consistency at various stages."
  },
  {
    "objectID": "posts/IRL-ToM-algorithms/index.html",
    "href": "posts/IRL-ToM-algorithms/index.html",
    "title": "Review article: Inverse Reinforcement Learning as the Algorithmic Basis for Theory of Mind",
    "section": "",
    "text": "Published in MDPI Algorithms\nOpen Access, DOI:10.3390/a16020068\n\nTheory of mind (ToM) is the psychological construct by which we model another’s internal mental states. Through ToM, we adjust our own behaviour to best suit a social context, and therefore it is essential to our everyday interactions with others. In adopting an algorithmic (rather than a psychological or neurological) approach to ToM, we gain insights into cognition that will aid us in building more accurate models for the cognitive and behavioural sciences, as well as enable artificial agents to be more proficient in social interactions as they become more embedded in our everyday lives. Inverse reinforcement learning (IRL) is a class of machine learning methods by which to infer the preferences (rewards as a function of state) of a decision maker from its behaviour (trajectories in a Markov decision process). IRL can provide a computational approach for ToM, as recently outlined by Jara-Ettinger, but this will require a better understanding of the relationship between ToM concepts and existing IRL methods at the algorthmic level. Here, we provide a review of prominent IRL algorithms and their formal descriptions, and discuss the applicability of IRL concepts as the algorithmic basis of a ToM in AI.\n\nCitation:\n@article{Ruiz-Serra2023InverseReinforcement,\n  title = {Inverse {{Reinforcement Learning}} as the {{Algorithmic Basis}} for {{Theory}} of {{Mind}}: {{Current Methods}} and {{Open Problems}}},\n  shorttitle = {Inverse {{Reinforcement Learning}} as the {{Algorithmic Basis}} for {{Theory}} of {{Mind}}},\n  author = {{Ruiz-Serra}, Jaime and Harr{\\'e}, Michael S.},\n  year = {2023},\n  month = feb,\n  journal = {Algorithms},\n  volume = {16},\n  number = {2},\n  pages = {68},\n  publisher = {{Multidisciplinary Digital Publishing Institute}},\n  issn = {1999-4893},\n  doi = {10.3390/a16020068}\n}"
  },
  {
    "objectID": "posts/vanishing-point-images/index.html",
    "href": "posts/vanishing-point-images/index.html",
    "title": "Finding the vanishing point in images",
    "section": "",
    "text": "%matplotlib inline\nimport cv2\nimport numpy as np\nimport urllib\nimport matplotlib.pyplot as plt\n\n\nFirst download a sample image.\ndef get_image_from_url(url):\n    \"\"\"https://stackoverflow.com/a/3969809\"\"\"\n\n    with urllib.request.urlopen(url) as u:\n        s = u.read()\n    arr = np.asarray(bytearray(s), dtype=np.uint8)\n    img = cv2.imdecode(arr, -1) # 'Load it as it is'\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\n    return img\n\nimg = get_image_from_url('https://static.toiimg.com/photo/69928969/cobble.jpg')\nplt.imshow(img)\n&lt;matplotlib.image.AxesImage at 0x7fb5ef127670&gt;\n\n\n\n\nWe are interested in using the most prominent edges in the image to compute the Hough lines. To find the edges, we use Canny edge detection.\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\nedges = cv2.Canny(gray, 200, 700)\n\nplt.imshow(edges, cmap='gray')\n&lt;matplotlib.image.AxesImage at 0x7fb5ef468e80&gt;\n\n\n\n\nWe can use the edges obtained above to compute Hough lines.\nlines = cv2.HoughLines(edges, 1, np.pi/180, 100)\nimg_lines = img.copy()\n\n# adapted from https://stackoverflow.com/a/60515853\nfor line in lines:\n    rho,theta = line[0]\n    a = np.cos(theta)\n    b = np.sin(theta)\n    x0 = a*rho\n    y0 = b*rho\n    x1 = int(x0 + 10000*(-b))\n    y1 = int(y0 + 10000*(a))\n    x2 = int(x0 - 10000*(-b))\n    y2 = int(y0 - 10000*(a))\n    cv2.line(img_lines, (x1,y1),(x2,y2),(0,255,0),2)\n    \nplt.imshow(img_lines)\n&lt;matplotlib.image.AxesImage at 0x7fb5da4183a0&gt;\n\nlines = cv2.HoughLines(edges, \n                       0.85, \n                       np.pi/180, \n                       100, \n                       # min_theta=np.pi/36, \n                       # max_theta=np.pi-np.pi/36\n                      )\n\nimg_lines = img.copy()\n\nsegments = []\nfor line in lines:\n    rho, theta = line[0]\n    # skip near-vertical lines\n    if abs(theta-np.pi/90) &lt; np.pi/9:\n        continue\n    \n    a = np.cos(theta)\n    b = np.sin(theta)\n    x0 = a*rho\n    y0 = b*rho\n    \n    x1 = int(x0 + 10000*(-b))\n    y1 = int(y0 + 10000*(a))\n    \n    x2 = int(x0 - 10000*(-b))\n    y2 = int(y0 - 10000*(a))\n    \n    segments.append((np.array((x1, y1)), \n                     np.array((x2, y2))))\n    \n    cv2.line(img_lines, (x1,y1),(x2,y2),(0,255,0),2)\n    \nplt.imshow(img_lines)\n&lt;matplotlib.image.AxesImage at 0x7fb5786558b0&gt;\n\ndef seg_intersect(s1, s2):\n    \"\"\"https://stackoverflow.com/a/3252222\"\"\"\n    da = s1[0] - s1[1]\n    db = s2[0] - s2[1]\n    dp = s1[0] - s2[0]\n    dap = perp(da)\n    denom = np.dot( dap, db)\n    num = np.dot( dap, dp )\n    return (num / denom.astype(float))*db + s2[0]\n\ndef perp(a):\n    b = np.empty_like(a)\n    b[0] = -a[1]\n    b[1] = a[0]\n    return b\n\nintersections = np.empty((len(segments), len(segments), 2))\nintersections[:] = np.nan\nfor i, s1 in enumerate(segments):\n    for j, s2 in enumerate(segments[i:], start=i):\n        if i != j:\n            intersections[i,j] = seg_intersect(s1, s2)\n\nintersections = intersections[~np.isnan(intersections)]\nintersections = intersections.reshape((int(len(intersections)/2), 2)).astype(np.int16)\nintersections\narray([[484, 332],\n       [522, 314],\n       [858, 157],\n       [550, 301],\n       [513, 318],\n       [523, 314],\n       [525, 313],\n       [477, 335],\n       [525, 307],\n       [776, 156],\n       [170, 520],\n       [509, 317],\n       [517, 312],\n       [524, 308],\n       [477, 336],\n       [587, 153],\n       [520, 318],\n       [519, 321],\n       [522, 314],\n       [524, 309],\n       [479, 422],\n       [800, 156],\n       [ 58, 144],\n       [103, 144],\n       [493, 151],\n       [474, 151],\n       [517, 320],\n       [526, 315],\n       [525, 315],\n       [477, 343],\n       [926, 477],\n       [527, 323],\n       [476, 304],\n       [525, 315],\n       [476, 295],\n       [472,  40]], dtype=int16)\nimg_points = img.copy()\n\n# show all intersection points\nfor p in intersections:\n    cv2.circle(img_points, (p[0], p[1]), 20, (255,0,0), 5)\n    \n# show mean intersection point\nvp_hat = np.mean(intersections, axis=0).astype(np.int16)\ncv2.circle(img_points, (vp_hat[0], vp_hat[1]), 20, (0,255,0), 5)\n\nplt.imshow(img_points)\n\nprint(f\"Estimated vanishing point coordinates:\", vp_hat)\nEstimated vanishing point coordinates: [513 285]"
  },
  {
    "objectID": "posts/vanishing-point-images/index.html#get-sample-image",
    "href": "posts/vanishing-point-images/index.html#get-sample-image",
    "title": "Finding the vanishing point in images",
    "section": "",
    "text": "First download a sample image.\ndef get_image_from_url(url):\n    \"\"\"https://stackoverflow.com/a/3969809\"\"\"\n\n    with urllib.request.urlopen(url) as u:\n        s = u.read()\n    arr = np.asarray(bytearray(s), dtype=np.uint8)\n    img = cv2.imdecode(arr, -1) # 'Load it as it is'\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\n    return img\n\nimg = get_image_from_url('https://static.toiimg.com/photo/69928969/cobble.jpg')\nplt.imshow(img)\n&lt;matplotlib.image.AxesImage at 0x7fb5ef127670&gt;"
  },
  {
    "objectID": "posts/vanishing-point-images/index.html#edge-detection",
    "href": "posts/vanishing-point-images/index.html#edge-detection",
    "title": "Finding the vanishing point in images",
    "section": "",
    "text": "We are interested in using the most prominent edges in the image to compute the Hough lines. To find the edges, we use Canny edge detection.\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\nedges = cv2.Canny(gray, 200, 700)\n\nplt.imshow(edges, cmap='gray')\n&lt;matplotlib.image.AxesImage at 0x7fb5ef468e80&gt;"
  },
  {
    "objectID": "posts/vanishing-point-images/index.html#hough-lines-from-edges",
    "href": "posts/vanishing-point-images/index.html#hough-lines-from-edges",
    "title": "Finding the vanishing point in images",
    "section": "",
    "text": "We can use the edges obtained above to compute Hough lines.\nlines = cv2.HoughLines(edges, 1, np.pi/180, 100)\nimg_lines = img.copy()\n\n# adapted from https://stackoverflow.com/a/60515853\nfor line in lines:\n    rho,theta = line[0]\n    a = np.cos(theta)\n    b = np.sin(theta)\n    x0 = a*rho\n    y0 = b*rho\n    x1 = int(x0 + 10000*(-b))\n    y1 = int(y0 + 10000*(a))\n    x2 = int(x0 - 10000*(-b))\n    y2 = int(y0 - 10000*(a))\n    cv2.line(img_lines, (x1,y1),(x2,y2),(0,255,0),2)\n    \nplt.imshow(img_lines)\n&lt;matplotlib.image.AxesImage at 0x7fb5da4183a0&gt;\n\nlines = cv2.HoughLines(edges, \n                       0.85, \n                       np.pi/180, \n                       100, \n                       # min_theta=np.pi/36, \n                       # max_theta=np.pi-np.pi/36\n                      )\n\nimg_lines = img.copy()\n\nsegments = []\nfor line in lines:\n    rho, theta = line[0]\n    # skip near-vertical lines\n    if abs(theta-np.pi/90) &lt; np.pi/9:\n        continue\n    \n    a = np.cos(theta)\n    b = np.sin(theta)\n    x0 = a*rho\n    y0 = b*rho\n    \n    x1 = int(x0 + 10000*(-b))\n    y1 = int(y0 + 10000*(a))\n    \n    x2 = int(x0 - 10000*(-b))\n    y2 = int(y0 - 10000*(a))\n    \n    segments.append((np.array((x1, y1)), \n                     np.array((x2, y2))))\n    \n    cv2.line(img_lines, (x1,y1),(x2,y2),(0,255,0),2)\n    \nplt.imshow(img_lines)\n&lt;matplotlib.image.AxesImage at 0x7fb5786558b0&gt;\n\ndef seg_intersect(s1, s2):\n    \"\"\"https://stackoverflow.com/a/3252222\"\"\"\n    da = s1[0] - s1[1]\n    db = s2[0] - s2[1]\n    dp = s1[0] - s2[0]\n    dap = perp(da)\n    denom = np.dot( dap, db)\n    num = np.dot( dap, dp )\n    return (num / denom.astype(float))*db + s2[0]\n\ndef perp(a):\n    b = np.empty_like(a)\n    b[0] = -a[1]\n    b[1] = a[0]\n    return b\n\nintersections = np.empty((len(segments), len(segments), 2))\nintersections[:] = np.nan\nfor i, s1 in enumerate(segments):\n    for j, s2 in enumerate(segments[i:], start=i):\n        if i != j:\n            intersections[i,j] = seg_intersect(s1, s2)\n\nintersections = intersections[~np.isnan(intersections)]\nintersections = intersections.reshape((int(len(intersections)/2), 2)).astype(np.int16)\nintersections\narray([[484, 332],\n       [522, 314],\n       [858, 157],\n       [550, 301],\n       [513, 318],\n       [523, 314],\n       [525, 313],\n       [477, 335],\n       [525, 307],\n       [776, 156],\n       [170, 520],\n       [509, 317],\n       [517, 312],\n       [524, 308],\n       [477, 336],\n       [587, 153],\n       [520, 318],\n       [519, 321],\n       [522, 314],\n       [524, 309],\n       [479, 422],\n       [800, 156],\n       [ 58, 144],\n       [103, 144],\n       [493, 151],\n       [474, 151],\n       [517, 320],\n       [526, 315],\n       [525, 315],\n       [477, 343],\n       [926, 477],\n       [527, 323],\n       [476, 304],\n       [525, 315],\n       [476, 295],\n       [472,  40]], dtype=int16)\nimg_points = img.copy()\n\n# show all intersection points\nfor p in intersections:\n    cv2.circle(img_points, (p[0], p[1]), 20, (255,0,0), 5)\n    \n# show mean intersection point\nvp_hat = np.mean(intersections, axis=0).astype(np.int16)\ncv2.circle(img_points, (vp_hat[0], vp_hat[1]), 20, (0,255,0), 5)\n\nplt.imshow(img_points)\n\nprint(f\"Estimated vanishing point coordinates:\", vp_hat)\nEstimated vanishing point coordinates: [513 285]"
  },
  {
    "objectID": "posts/end-exporting-entropy-obscuring-accountability/index.html",
    "href": "posts/end-exporting-entropy-obscuring-accountability/index.html",
    "title": "An End to Exporting Entropy and Obscuring Accountability",
    "section": "",
    "text": "Poverty, as defined by the World Bank, includes a shortfall in income and consumption, poor health and nutritional outcomes, low educational attainment, lack of access to basic services, and a hazardous living environment. It is widely accepted that globalisation is a major contributing factor to the causes of poverty. If we are to mitigate its effects, a change in the personal values and outlook of all involved in capitalism is required. Through this essay I argue that a change in our attitudes, based on a syncretisation of Epicurean virtue ethics and secular Buddhist practices, can provide the necessary course correction for a more equitable and sustainable system within the context of capitalism.\nProjections by the World Bank estimate that, by the year 2030, the number of people in extreme poverty in Asia will be vastly reduced. On the other hand, their projections also estimate the number of people in extreme poverty to grow in Africa and the Middle East, and to remain the same in Latin America World Bank Group (2018). In an age where some of us can summon just about any kind (and amount) of food to our doorstep with a few finger swipes and taps, and subsequently make the resulting detritus vanish (without bothering to separate it for recycling or thinking about where it goes), these numbers are appalling.\nAnd yet, since all that is required for those born into privilege to opt into this lifestyle is little more than going through the motions of the Hobbesian social contract, they see no incentive to change their ways nor the system they are part of. Thus new generations go on to become gears in the neoliberal machine, which has its foundations in imperialist colonialism, emerging in the 16th century alongside the mechanistic view that saw nature as something to be subjugated, exacerbated by misconstruing John Locke’s property rights1, and which continues to this date to instigate poverty and depletion of natural resources. The exporting of entropy and obscuring of accountability are key features of the sleight of hand—the invisible hand—with which neoliberalism perpetrates systematic, large scale manslaughter2 Leech (2012).\nThe locus of a metaphysics we use needs to be at the human level. Although the selfish gene proposed by Richard Dawkins, based on Darwinism, is a compelling explanation of the behaviours in nature, I believe humans have reached an evolutionary point where we have the ability to overcome the tyranny of the gene, thereby asserting our freedom of will3.\nArguably neoliberalism claims its legitimacy in utilitarian terms. The issue is not so much with utilitarianism itself, but in the fact that neoliberalism seems to have (once again) misconstrued the maxim “the greatest good for the greatest number”, somehow disregarding the “greatest number” while obsessing over a delusional idea of what the “greatest good” is4. Instead, if it is to work on a utilitarian basis, our system ought to satisfice the quantifiable good while maximising the greatest number (all humanity in principle, without falling into the moronic notion that in order to truly maximise the number we should encourage growth in population). Additionally, the prevailing use of utilitarianism is in Bentham’s purely hedonistic terms. Mill, for instance, provided a more subtle way of evaluating our actions, with an emphasis on higher pleasures such as intellectual pursuits. Consequentialism has its strengths and can be useful given that we are more capable than ever to model and predict the consequences of our actions5, but we need to look beyond pleasure and tangible utility, as well as take other viewpoints into account, embracing complexity and uncertainty.\nThe functioning of this system is based on the Cartesian solipsistic proposition “je pense, donc je suis”, which reinforces Hobbes’ notion of society as a mere collection of individuals. Although Hobbes presupposed psychological egoism when coming up with this notion, arguably this point of departure if anything makes the individual egotistic, thus the initial conditions for the master–slave dialectic arise. Here, Hegel’s view of the dialectic of recognition offers a more sophisticated understanding of our place in society in relation to the “other”. We cannot isolate ourselves from other conscious subjects, as the very foundations of our thinking are in language, which would not exist were it not for the rest of humans, past and present. Neither would education, conventions, culture; nor capitalism as we know it, for the state of luxury in the global North would not have been possible without colonialism, slavery and control of foreign countries through insidious methods. We must see ourselves reflected in other people, and as long as there are people struggling to feed themselves and we fail to recognise their lack of freedom, we cannot ourselves be free. And it is not only the global South that fits the role of the slave in this dialectic. Privileged people in the global North are made to feel like they are not enough by the system by design.\nUnrealistic expectations and the exploiting of the path of least resistance—characteristic of neoliberalism—have severed our connection with our community and damaged our sense of identity, bringing about impostor syndrome, depression, loneliness, envy and a self-perpetuating craving for acceptance and belonging, which we seek (and continue to fail) to fulfill through consumption. Immanuel Kant placed man as an end in itself, never to be a means. In the current system, people seem to be a means to the end of accumulation of capital. His student Herder asserted that the end of life is not satisfying appetites, but teleological self-realisation. For him, humans are “essentially social and cultural, involved in a struggle to identify their own and their communities’ unique centers of gravity and to realise their unique potentials” Gare (2009). It is evident that these two notable figures of Ethics would find neoliberalism morally objectionable not only on grounds of its consequences, but of its intentions foremost.\nHerder said the end of life is self-realisation Gare (2009). Our systems need to enable everyone to pursue self-realisation, so we need to eliminate the barrier of poverty. Need to elevate everyone along Maslow’s hierarchy of needs. Herder also said humans are social, cultural beings. Our bonds with our community and culture need to be strengthened, not weakened or fragmented as it has been done by so called “social media”, which robs us of our quality time with the people we care about and of taking our part in our local community.\nIn Luther’s time, freedom from God’s punishment being sold as a commodity. His reaction was to attempt to “cut the middle man” using the latest technology at the time (printing) to make relevant knowledge (the Bible) accessible to more people. Capitalism sells (fleeting) freedom to a void that is continually created in us by it, so perhaps we could employ technology to empower smaller communities in order to cut the capitalist middle man. An important consideration however is that these communities must be self-sufficient and mutually respectful to avoid conflicts and wars as happened as a result of Luther’s reformations.\nIf population growth is curbed and we do not succumb to the artificial increase of our “needs” by means of advertising, the capitalist complex will need to turn to the developing countries for new customers Leech (2012), and come up with more sustainable practices to ensure its continuity. Thus the effect of strengthening our sense of community and friendship and pursuing a more modest lifestyle is two-fold in combating alienation: it creates a direct connection with those around us, removing our need to participate in consumerism to delude ourselves that we are engaged; and in the long run could mean the reincorporation of those who, due to a shortcoming of purchasing power, are most alienated by the system Monbiot (2016).\nOrganisation in smaller communities means that everyone in them matters, removing some of the envy and competition that are so pervasive in the current system (and which breed fanaticism and extremism and engender terrorism and violence). The “reachable” scope of a smaller community also creates optimism because its members feel more accountable and empowered. This is crucial to combat the apathy and disenfranchisement the stems from a feeling of helplessness. Small-scale economical activity entails heterogeneous complexity, sign of a healthy state of “life at the edge of chaos”. The benefits of more localised and self-sufficient economies have been defended by the likes of Bookchin, Chomsky, and most recently Norberg-Hodge Norberg-Hodge (2019):\nThat is not to say we should abolish all global-scale activity. Rather, we need to question the legitimacy of transnational corporations and their “value-adding”, quantified beyond economic terms; while encouraging universal opening of intellectual property and knowledge sharing in general, to be applied at a local scale for the benefit of all communities.\nHumanity as a whole has reached a point—through collaboration and many sacrifices—where our knowledge and technological and scientific ability should be sufficient to provide the material necessities required for everyone to live a good life, should they be employed effectively. Our fear of uncertainty Saul (2002) manifests in the feeling that we can protect ourselves against it by means of accumulating capital as a “buffer”. The right mechanisms in place at a systemic level to make people feel safe—welfare, a strong sense of community—should encourage individuals to let go of this need for a buffer. But this is not enough. A way to justify opulence and luxury is in saying that “the aspiration to luxury is experienced as a manifestation of freedom” Mendonça (2020), but when this aspiration turns into bondage of ourselves and others through debt and competition, it is hard to find value in it.\nJust as the radical enlightenment strove to revive Greek philosophy with egalitarian distribution of wealth based on harmony between man and nature McLaren (2020), so can we build upon the virtue ethics of the ancient Greeks. A particularly fitting way of life is that suggested by Epicurus, whereby the greatest good is in seeking modest pleasures in order to attain a state of tranquillity, freedom from fear, and absence of pain. The Epicurean life placed major emphasis on friendship (in which we find security), community and rituals, self-sufficiency and being content with little, and pedagogy Konstan (2018). Furthermore, the Epicureans advocated for work that focused on improving the world and helping others, in small groups with a strong team spirit. For them, making a difference was far more important and meaningful than status. This way of life would debilitate the mechanisms that perpetuate poverty and free up resources that could be directed at eradicating it, whilst mitigating some of the adverse effects of the system on the individual.\nIn Buddhism, craving and ignorance are the main causes of suffering. Buddhist teachings lay down the necessary steps to transcend suffering through a change in our outlook, not our circumstances, and achieve equanimity. By realising that suffering is present in everyone’s lives, compassion for others is cultivated. It acknowledges that everything is changing constantly (not unlike Whitehead’s process philosophy), and focuses on providing precepts to act in ways beneficial to ourselves and others. These are not rules to be taken as dogma, but rather guides to be interpreted and explored freely and sensibly. The complexity of the world is acknowledged, and therefore there is no right or wrong, but rather “skillful” and “unskillful” ways to deal with situations.\nThe avoidance of luxury is encouraged, but not to the extreme of asceticism, striving for what is called the Middle Way (not unlike Aristotle’s Golden Mean), and setting aside the pleasing illusions that we adopt to make life comfortable. Secular Buddhism places its emphasis on introspection, satisfaction through acceptance, and the interconnectedness of all things in the cosmos (not unlike Hegel’s dialectic of recognition). There is a remarkable overlap between Epicureanism and Buddhism, and they complement each other providing a compelling ethics for a transition out of the destructive effects of neoliberalism, from the bottom up.\nRecent studies in psychology Rand, Greene, and Nowak (2012) support Russeau in thinking that people are inherently good Rousseau (1984). By tackling poverty, alienation, hopelessness, abuse, and oppression; with a focus on virtue, small-scale local action, education, role models, a change in our desires, and technology in the service of people; we can reduce people’s “reasons” to act immorally and redirect our course as a species toward a good life for everyone."
  },
  {
    "objectID": "posts/end-exporting-entropy-obscuring-accountability/index.html#footnotes",
    "href": "posts/end-exporting-entropy-obscuring-accountability/index.html#footnotes",
    "title": "An End to Exporting Entropy and Obscuring Accountability",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHe did say that people should claim no property for which they have not laboured, and take only their fair share.↩︎\nThe Encyclopaedia Britannica defines crimes against humanity as those “committed as part of a widespread or systematic attack directed against any civilian population”.↩︎\nAs discussed in relation to the principle of least action, in an earlier article.↩︎\nHint: it is not the use of capital in order to obtain more capital.↩︎\nSee Bhutan’s Gross National Happiness Index, or the Genuine Progress Indicator.↩︎"
  },
  {
    "objectID": "posts/ACM-TOMM-selfattention/index.html",
    "href": "posts/ACM-TOMM-selfattention/index.html",
    "title": "Learning scene representations for human-assistive displays using self-attention networks",
    "section": "",
    "text": "Published in ACM Transactions on Multimedia Computing, Communications, and Applications\nFree access, DOI:10.1145/3650111\n\nVideo-see-through (VST) augmented reality (AR) is widely used to present novel augmentative visual experiences by processing video frames for viewers. Among VST AR systems, assistive vision displays aim to compensate for low vision or blindness, presenting enhanced visual information to support activities of daily living for the vision impaired/deprived. Despite progress, current assistive displays suffer from a visual information bottleneck, limiting their functional outcomes compared to healthy vision. This motivates the exploration of methods to selectively enhance and augment salient visual information. Traditionally, vision processing pipelines for assistive displays rely on hand-crafted, single-modality filters, lacking adaptability to time-varying and environment-dependent needs. This paper proposes the use of Deep Reinforcement Learning (DRL) and Self-attention (SA) networks as a means to learn vision processing pipelines for assistive displays. SA networks selectively attend to task-relevant features, offering a more parameter- and compute-efficient approach to RL-based task learning. We assess the feasibility of using SA networks in a simulation-trained model to generate relevant representations of real-world states for navigation with prosthetic vision displays. We explore two prosthetic vision applications, vision-to-auditory encoding, and retinal prostheses, using simulated phosphene visualisations. This paper introduces SA-px, a general-purpose vision processing pipeline using self-attention networks, and SA-phos, a display-specific formulation targeting low-resolution assistive displays. We present novel scene visualisations derived from SA image patches importance rankings to support mobility with prosthetic vision devices. To the best of our knowledge, this is the first application of self-attention networks to the task of learning vision processing pipelines for prosthetic vision or assistive displays.\n\nCitation:\n@article{10.1145/3650111,\nauthor = {Ruiz-Serra, Jaime and White, Jack and Petrie, Stephen and Kameneva, Tatiana and McCarthy, Chris},\ntitle = {Learning scene representations for human-assistive displays using self-attention networks},\nyear = {2024},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nissn = {1551-6857},\nurl = {https://doi.org/10.1145/3650111},\ndoi = {10.1145/3650111},\nnote = {Just Accepted},\njournal = {ACM Trans. Multimedia Comput. Commun. Appl.},\nmonth = {mar},\nkeywords = {vision processing, deep reinforcement learning, prosthetic vision, display algorithms}\n}"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "Translating an unwieldy codebase\n\n\n2 min\n\n\n\n\n\n\nMar 16, 2024\n\n\n\n\n\n\n\n\n\n\n\nLearning scene representations for human-assistive displays using self-attention networks\n\n\n2 min\n\n\n\n\n\n\nMar 3, 2024\n\n\n\n\n\n\n\n\n\n\n\nGitHub Copilot AI for free (for students and academics)\n\n\n1 min\n\n\n\n\n\n\nFeb 23, 2024\n\n\n\n\n\n\n\n\n\n\n\nComplexity, Criticality, Computation Symposium (C3) 2023\n\n\n1 min\n\n\n\n\n\n\nJan 23, 2023\n\n\n\n\n\n\n\n\n\n\n\nReview article: Inverse Reinforcement Learning as the Algorithmic Basis for Theory of Mind\n\n\n2 min\n\n\n\n\n\n\nJan 19, 2023\n\n\n\n\n\n\n\n\n\n\n\nFinding the vanishing point in images\n\n\n6 min\n\n\n\n\n\n\nOct 5, 2021\n\n\n\n\n\n\n\n\n\n\n\nAn End to Exporting Entropy and Obscuring Accountability\n\n\n12 min\n\n\n\n\n\n\nMay 31, 2020\n\n\n\n\n\n\n\n\n\n\n\nTowards an Ecological Ethics\n\n\n4 min\n\n\n\n\n\n\nMay 4, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/towards-ecological-ethics/index.html",
    "href": "posts/towards-ecological-ethics/index.html",
    "title": "Towards an Ecological Ethics",
    "section": "",
    "text": "As I leave the comfort of my desk to go grocery shopping, I face, week after week, the following dilemma. On one hand, I would like to spend as little as possible in order to ensure I can continue to pay my university fees, rent, bills and the like. “Perhaps I might even be able to do some travel if I am conservative enough with my spending”, is my teleological rationale. On the other hand, I am aware that cheaper consumer products often come at a cost of being less healthy, produced by big industrial corporations, and more damaging to the environment (for instance, using unsustainable ingredients like palm oil, overseas manufacturing and its carbon footprint, and/or cheaper non-recyclable packaging).\nThe industrial complex, as a system, requires input (capital, raw materials) to produce its output and continue to thrive. Consumers provide the capital and nature provides the raw materials. In the process, they become instruments for the production of prestige goods and weapons in the interest of domination by the ruling class Gare (2010). One of the astonishing phenomena by which this dynamic is perpetuated are heavily processed foods. These are a manifestation of our technological prowess, in the sense that they exploit the principle of least action, whereby systems (in this case, humans) have a tendency to increase their potential energy while trying to minimise any action (e.g. movement) Feynman (1964), Das (2013). The consumption of such products is made easy by their cheap and time-saving qualities (both in the preparation and procuring thereof) Pollan (2013).\nClosely related to the principle of least action is entropy, or amount of chaos. The second law of thermodynamics states that “the entropy in an isolated system can increase but not decrease” Wehrl (1978). Open thermodynamic systems such as living organisms, however, are able to reduce their local entropy through increasing that of their environment, with a resultant net increase in entropy overall1. Thus once again humanity as a whole—by means of industrial streamlining of production—continues to exploit this phenomenon to our immediate benefit and long term detriment of our habitat (and, unwittingly, of ourselves).\nSo we find ourselves at a critical time at the edge of chaos McLaren (2009). Within the limited conditions in which life and order are possible, equilibrium is delicate2. We need to change our ways to ensure the long term prosperity of our environment (and through it, of ourselves). I believe that a powerful way in which we can assert our free will is by acting against the principle of least action.\nWe are privileged to have a wealth of knowledge and connectedness at our disposal (largely as a result of industrial civilisation), which we can deploy as local, small scale, sustainable production of sustenance and goods, working in communities within communities, as suggested by the likes of Chomsky Chomsky and Foucault (1971), and Bookchin Bookchin (1987).\nIn order to make an impact in the correction of our course as a species, a critical mass of people willing to inspire change is required. It is our role as thinkers to convince our fellow humans that everyone has a stake, that democracy manifests in subtle ways, and that every action counts. A way to inspire people to act might be to romanticise production as we have consumption—for which we would have to overcome the principle of least action—making it desirable, commendable. This is achievable through an Aristotelian virtue ethics."
  },
  {
    "objectID": "posts/towards-ecological-ethics/index.html#footnotes",
    "href": "posts/towards-ecological-ethics/index.html#footnotes",
    "title": "Towards an Ecological Ethics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt is important to note here that there is no escaping the arrow of time Hawking (2009). It points in the direction of entropy increasing, hence why the scattered pieces on the ground come after the vase being on the shelf, and not the other way around.↩︎\nI invite the reader to consider the relationship between complexity and entropy, as outlined in Rosso et al. (2007).↩︎"
  },
  {
    "objectID": "coffee.html",
    "href": "coffee.html",
    "title": "Barista days",
    "section": "",
    "text": "Auto Espresso\nAuto Espresso was a specialty coffee bar within Autonomy Clothing’s Melbourne CBD flagship store. Our coffee and friendliness was a favourite amongst both shoppers and employees at the Emporium in Melbourne.\n\nI was on the “cover” of a print run of leaflets for the Emporium Melbourne.\n\n\n\n\n\n\nGeneral Order\nGeneral Order was a barbershop in Richmond, Melbourne, where I served coffee and sweet treats as well as assisted with bookings and customer service for the barbershop.\n\n\nI also enjoy cooking and baking sourdough bread."
  },
  {
    "objectID": "faq.html",
    "href": "faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "How do you pronounce your name?\n\n[ˈxajme] sounds like HI-may.\n\n\n\nWhat tools do you use for your research?\n\nI use a MacBook Pro:\n\nZotero: reference manager\nObsidian.md: note editor\nVS Code: code editor\nOverleaf: text processor for research manuscripts\nQuarto: for Markdown presentation slides (and this website!)\nBrave: internet browser\nToggl: time tracker and an Android phone:\nMoon+ Reader Pro: epub and PDF reader\nGlance: syntax highlighting for macOS quicklook"
  }
]